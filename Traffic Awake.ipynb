{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb98e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "from io import BytesIO\n",
    "from IPython.display import clear_output, Image, display\n",
    "from PIL import Image as Img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b965d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código para captura de vídeo\n",
    "\n",
    "def padronizar_imagem(frame):\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (500, 400))\n",
    "    return frame\n",
    "\n",
    "def exibir_video(frame):\n",
    "    img = Img.fromarray(frame, \"RGB\")\n",
    "    buffer = BytesIO()\n",
    "    img.save(buffer, format=\"JPEG\")\n",
    "    display(Image(data=buffer.getvalue()))\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "945f0820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instância modelo dlib\n",
    "\n",
    "classificador_path = \"classificadores/shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "classificador_dlib = dlib.shape_predictor(classificador_path)\n",
    "\n",
    "# Método dlib para reconhecimento facial\n",
    "detector_face = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566abf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constantes de marcos faciais\n",
    "\n",
    "FACE = list(range(17, 68))\n",
    "FACE_COMPLETA = list(range(0, 68))\n",
    "LABIO = list(range(48, 61))\n",
    "SOMBRANCELHA_DIREITA = list(range(17, 22))\n",
    "SOMBRANCELHA_ESQUERDA = list(range(22, 27))\n",
    "OLHO_DIREITO = list(range(36, 42))\n",
    "OLHO_ESQUERDO = list(range(42, 48))\n",
    "NARIZ = list(range(27, 35))\n",
    "MANDIBULA = list(range(0, 17))\n",
    "\n",
    "# Método para ler o vídeo e obter marcos faciais \n",
    "\n",
    "def pontos_marcos_faciais(imagem):\n",
    "    retangulos = detector_face(imagem, 1)\n",
    "\n",
    "    if len(retangulos) == 0:\n",
    "        return None\n",
    "\n",
    "    marcos = []\n",
    "\n",
    "    for retangulo in retangulos:\n",
    "        marcos.append(np.matrix([[p.x, p.y] for p in classificador_dlib(imagem, retangulo).parts()]))\n",
    "\n",
    "    return marcos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c9b7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distância euclidiana para verificar abertura olhos\n",
    "\n",
    "def EAR(pontos_olhos):\n",
    "    \n",
    "    a = dist.euclidean(pontos_olhos[1], pontos_olhos[5])\n",
    "    b = dist.euclidean(pontos_olhos[2], pontos_olhos[4])\n",
    "    c = dist.euclidean(pontos_olhos[0], pontos_olhos[3])\n",
    "    \n",
    "    aspecto_razao = (a + b)/(2.0 * c)\n",
    "    \n",
    "    return aspecto_razao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e370e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anotar_marcos(imagem, marcos):\n",
    "    retangulos = detector_face(imagem, 1)\n",
    "    \n",
    "    if len(retangulos) == 0:\n",
    "        return None\n",
    "    \n",
    "    for idx, ret in enumerate(retangulos):\n",
    "        marco = marcos[idx]\n",
    "        \n",
    "        pontos = cv2.convexHull(marco[OLHO_ESQUERDO])\n",
    "        cv2.drawContours(imagem, [pontos], 0, (0,255,0), 2)\n",
    "        \n",
    "        pontos = cv2.convexHull(marco[OLHO_DIREITO])\n",
    "        cv2.drawContours(imagem, [pontos], 0, (0,255,0), 2)\n",
    "    \n",
    "    return imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d313f877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrompido\n"
     ]
    }
   ],
   "source": [
    "# Detecção olhos\n",
    "\n",
    "try:\n",
    "    video = cv2.VideoCapture(0)\n",
    "    \n",
    "    while(True):\n",
    "        captura_ok, frame = video.read()\n",
    "        frame = padronizar_imagem(frame)\n",
    "        \n",
    "        marcos_faciais = pontos_marcos_faciais(frame)\n",
    "        \n",
    "        if marcos_faciais is not None:\n",
    "            ar_olho_esq = EAR(marcos_faciais[0][OLHO_ESQUERDO])\n",
    "            ar_olho_dir = EAR(marcos_faciais[0][OLHO_DIREITO])\n",
    "            \n",
    "            ar_olho_esq = round(ar_olho_esq, 3)\n",
    "            ar_olho_dir = round(ar_olho_dir, 3)\n",
    "            \n",
    "            info_oe = \"EAR Olho Esquerdo \" + str(ar_olho_esq)\n",
    "            info_od = \"EAR Olho Direito \" + str(ar_olho_dir) \n",
    "            \n",
    "            frame = anotar_marcos(frame, marcos_faciais)\n",
    "            \n",
    "            cv2.putText(frame, info_oe, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2)\n",
    "            cv2.putText(frame, info_od, (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2)\n",
    "            \n",
    "        exibir_video(frame)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    video.release()\n",
    "    print(\"Interrompido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e09759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
